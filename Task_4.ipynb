{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3e21e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy\n",
    "import mandelbrot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02395e47",
   "metadata": {},
   "source": [
    "#### Define subarea class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3986c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subarea:\n",
    "    \n",
    "    def __init__(self, par_a, par_i, prob):\n",
    "        \n",
    "        # Create a mandelbrot object for this area\n",
    "        self.mandel = mandelbrot.mandel(par_a)\n",
    "        \n",
    "        # Edges of the subarea\n",
    "        self.x_min = par_a[0]\n",
    "        self.x_max = par_a[1]\n",
    "        self.y_min = par_a[2]\n",
    "        self.y_max = par_a[3]\n",
    "        \n",
    "        # Sampling probability\n",
    "        self.probability = prob\n",
    "        self.iterations = par_i\n",
    "        \n",
    "        # Variable that indicates if the probability should be increased\n",
    "        self.prob_incr = False\n",
    "    \n",
    "    def subdivide(self, n_subareas):\n",
    "        \n",
    "        # Set the initial coordinates at the minimal value\n",
    "        x_min = self.x_min\n",
    "        x_max = self.x_min\n",
    "        y_min = self.y_min\n",
    "        y_max = self.y_min\n",
    "        \n",
    "        # List to store the newly created subareas\n",
    "        new_subareas = []\n",
    "        # Equally distribute the sampling probability over the subareas\n",
    "        new_prob = self.probability / n_subareas\n",
    "        \n",
    "        # Calculate the length of the subareas\n",
    "        distance_x = (self.x_max - self.x_min) / np.sqrt(n_subareas)\n",
    "        distance_y = (self.y_max - self.y_min) / np.sqrt(n_subareas)\n",
    "        \n",
    "        # Determine the edges of the subareas\n",
    "        for _ in range(int(np.sqrt(n_subareas))):\n",
    "            # The minimal value is the maximal value of the previous subarea\n",
    "            x_min = x_max\n",
    "            x_max += distance_x\n",
    "            \n",
    "            for _ in range(int(np.sqrt(n_subareas))):\n",
    "                y_min = y_max\n",
    "                y_max += distance_y\n",
    "                \n",
    "                # Create subarea\n",
    "                new_subareas.append(subarea([x_min, x_max, y_min, y_max], self.iterations, new_prob))\n",
    "            \n",
    "            y_min = self.y_min\n",
    "            y_max = self.y_min\n",
    "        \n",
    "        return new_subareas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38f3e8",
   "metadata": {},
   "source": [
    "#### Creating subareas \n",
    "The following two cells create 100 area estimations using strategic sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5d2d1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = [-2, 2, -2, 2]\n",
    "start_iter = 400\n",
    "start_samples =256\n",
    "repeats = 100\n",
    "cycles = 6\n",
    "starting_subdivisions = 16\n",
    "subdivisions = 4\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b41634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_samplepoints = np.zeros((repeats))\n",
    "col_est_areas_ss = np.zeros((repeats,cycles))\n",
    "\n",
    "st = time.time()\n",
    "for j in range(repeats):\n",
    "    subspaces = subarea(area, start_iter, 1)\n",
    "    subspaces = subspaces.subdivide(starting_subdivisions)\n",
    "    samplepoints_ss = []\n",
    "    est_areas = []\n",
    "    # Improve sampling locations 5 times\n",
    "    for n in range(cycles):\n",
    "\n",
    "        prob_decr = 0           # Total probability decrease over all the subareas\n",
    "        n_areas_incr = 0        # Number of subareas for which the probability should increase\n",
    "        total_mandel_area = 0\n",
    "        points = np.empty(0)\n",
    "        loc_samples = start_samples* (2**n)\n",
    "        for subspace in subspaces:\n",
    "\n",
    "            # Determine number of samples in subarea\n",
    "            n_samples = max(int(subspace.probability * loc_samples), 1)\n",
    "            # Calculate the mandelbrot area in the subarea\n",
    "            mandel_area, samples = subspace.mandel.est_area(n_samples, subspace.iterations, method = 'latin_hypercube')\n",
    "            total_mandel_area += mandel_area\n",
    "\n",
    "            # Store the samplepoints\n",
    "            if len(points) == 0:\n",
    "                points = samples\n",
    "            else:\n",
    "                points = np.concatenate((points, samples))\n",
    "\n",
    "\n",
    "            if mandel_area == 0:\n",
    "                # Areas outside of the Mandelbrot set\n",
    "                subspace.iterations = start_iter \n",
    "                subspace.probability /= 2\n",
    "                prob_decr += subspace.probability\n",
    "\n",
    "            elif mandel_area == subspace.mandel.area:\n",
    "                # Areas inside of the Mandelbrot set\n",
    "                subspace.probability /= 2\n",
    "                prob_decr += subspace.probability\n",
    "\n",
    "            else:\n",
    "                # Areas on the edge of the Mandelbrot set\n",
    "                subspace.iterations = start_iter * (n + 1) \n",
    "                subspace.prob_incr = True\n",
    "                n_areas_incr += 1\n",
    "        # Increase the probability of the important areas\n",
    "        add_prob = prob_decr / n_areas_incr\n",
    "        new_subspaces = []\n",
    "\n",
    "        for subspace in subspaces:\n",
    "            if subspace.prob_incr == True:\n",
    "                subspace.probability += add_prob\n",
    "                subspace.prob_incr = False\n",
    "\n",
    "            # Subdivide the areas every other iteration\n",
    "            if n % 2 == 0:\n",
    "                new_subareas = subspace.subdivide(subdivisions)\n",
    "                new_subspaces += new_subareas\n",
    "\n",
    "        if n % 2 == 0:\n",
    "            subspaces = new_subspaces\n",
    "\n",
    "        # Store the all the sampling points in this iteration\n",
    "        samplepoints_ss.append(points)\n",
    "        # Store the estimated area\n",
    "        est_areas.append(total_mandel_area)\n",
    "    \n",
    "    \n",
    "    \n",
    "    col_est_areas_ss[j] = est_areas\n",
    "        \n",
    "print(st-time.time(),\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ceb57",
   "metadata": {},
   "source": [
    "The following two cells create 100 area estimations using basic Monte Carlo Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1454c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = [-2, 2, -2, 2]\n",
    "start_iter = 400\n",
    "start_samples =256\n",
    "repeats = 100\n",
    "cycles = 6\n",
    "starting_subdivisions = 1\n",
    "subdivisions = 1\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_samplepoints = np.zeros((repeats))\n",
    "col_est_areas_mc = np.zeros((repeats,cycles))\n",
    "\n",
    "st = time.time()\n",
    "for j in range(repeats):\n",
    "    subspaces = subarea(area, start_iter, 1)\n",
    "    subspaces = subspaces.subdivide(starting_subdivisions)\n",
    "    samplepoints_mc = []\n",
    "    est_areas = []\n",
    "    # Improve sampling locations 5 times\n",
    "    for n in range(cycles):\n",
    "\n",
    "        prob_decr = 0           # Total probability decrease over all the subareas\n",
    "        n_areas_incr = 0        # Number of subareas for which the probability should increase\n",
    "        total_mandel_area = 0\n",
    "        points = np.empty(0)\n",
    "        loc_samples = start_samples* (2**n)\n",
    "        for subspace in subspaces:\n",
    "\n",
    "            # Determine number of samples in subarea\n",
    "            n_samples = max(int(subspace.probability * loc_samples), 1)\n",
    "            # Calculate the mandelbrot area in the subarea\n",
    "            mandel_area, samples = subspace.mandel.est_area(n_samples, subspace.iterations, method = 'latin_hypercube')\n",
    "            total_mandel_area += mandel_area\n",
    "\n",
    "            # Store the samplepoints\n",
    "            if len(points) == 0:\n",
    "                points = samples\n",
    "            else:\n",
    "                points = np.concatenate((points, samples))\n",
    "\n",
    "\n",
    "            if mandel_area == 0:\n",
    "                # Areas outside of the Mandelbrot set\n",
    "                subspace.iterations = start_iter \n",
    "                subspace.probability /= 2\n",
    "                prob_decr += subspace.probability\n",
    "\n",
    "            elif mandel_area == subspace.mandel.area:\n",
    "                # Areas inside of the Mandelbrot set\n",
    "                subspace.probability /= 2\n",
    "                prob_decr += subspace.probability\n",
    "\n",
    "            else:\n",
    "                # Areas on the edge of the Mandelbrot set\n",
    "                subspace.iterations = start_iter * (n + 1) \n",
    "                subspace.prob_incr = True\n",
    "                n_areas_incr += 1\n",
    "        # Increase the probability of the important areas\n",
    "        add_prob = prob_decr / n_areas_incr\n",
    "        new_subspaces = []\n",
    "\n",
    "        for subspace in subspaces:\n",
    "            if subspace.prob_incr == True:\n",
    "                subspace.probability += add_prob\n",
    "                subspace.prob_incr = False\n",
    "\n",
    "            # Subdivide the areas every other iteration\n",
    "            if n % 2 == 0:\n",
    "                new_subareas = subspace.subdivide(subdivisions)\n",
    "                new_subspaces += new_subareas\n",
    "\n",
    "        if n % 2 == 0:\n",
    "            subspaces = new_subspaces\n",
    "\n",
    "        # Store the all the sampling points in this iteration\n",
    "        samplepoints_mc.append(points)\n",
    "        # Store the estimated area\n",
    "        est_areas.append(total_mandel_area)\n",
    "    \n",
    "    \n",
    "    \n",
    "    col_est_areas_mc[j] = est_areas\n",
    "        \n",
    "print(st-time.time(),\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa255a",
   "metadata": {},
   "source": [
    "#### Statistical tests\n",
    "The following cell contains the statistical tests for Hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mandelbrot_area = 1.506484\n",
    "#Mean of the area estimation\n",
    "mean_area_estimate_ss = np.mean(col_est_areas_ss,axis=0)\n",
    "mean_area_estimate_mc = np.mean(col_est_areas_mc,axis=0)\n",
    "\n",
    "#Standard deviation of area estimation\n",
    "std_area_estimate_ss = np.std(col_est_areas_ss,axis=0)\n",
    "std_area_estimate_mc = np.std(col_est_areas_mc,axis=0)\n",
    "\n",
    "#Variance of area estimation\n",
    "var_area_estimate_ss = np.var(col_est_areas_ss,axis=0)\n",
    "var_area_estimate_mc = np.var(col_est_areas_mc,axis=0)\n",
    "\n",
    "#Welch's T test created from the slides in the lectures\n",
    "welch_t =abs(mean_area_estimate_ss- mean_area_estimate_mc)/np.sqrt(var_area_estimate_ss/repeats + var_area_estimate_mc/repeats)\n",
    "welch_df = np.divide(np.power(var_area_estimate_ss/repeats + var_area_estimate_mc/repeats,2),np.power(var_area_estimate_ss/repeats,2)/(repeats-1) + np.power(var_area_estimate_mc/repeats,2)/(repeats-1))\n",
    "welch_critical_value = [scipy.stats.t.ppf(q=1-.01,df=loc_welch_df) for loc_welch_df in welch_df]\n",
    "\n",
    "#F-test Value\n",
    "F_tdivide= np.divide(var_area_estimate_mc,var_area_estimate_ss)\n",
    "\n",
    "#formatting array\n",
    "x_axis = np.arange(cycles) +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3049b80",
   "metadata": {},
   "source": [
    "#### Plot: Mean comparisson with 1-sigma Confidence intervals using Monte Carlo/ Strategic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.plot(x_axis,mean_area_estimate_ss,\"g-\",label =\"Mean Strategic sampling\")\n",
    "plt.plot(x_axis,mean_area_estimate_mc,\"b-\",label =\"Mean Monte Carlo\")\n",
    "plt.title(\"Mean comparisson with 1-sigma Confidence intervals using Monte Carlo/ Strategic Sampling\", loc='bottom')\n",
    "plt.ylabel(\"Estimated Area\")\n",
    "plt.xlabel(\"Cycle\")\n",
    "plt.axhline(num_mandelbrot_area)\n",
    "plt.legend()\n",
    "ax.fill_between(x_axis,mean_area_estimate_ss -std_area_estimate_ss,mean_area_estimate_ss +std_area_estimate_ss, color='tab:green', alpha=0.2)\n",
    "ax.fill_between(x_axis,mean_area_estimate_mc -std_area_estimate_mc,mean_area_estimate_mc +std_area_estimate_mc, color='tab:blue', alpha=0.2)\n",
    "#plt.ylim(-2,2)\n",
    "#plt.xlim(-2,2\n",
    "plt.tight_layout()\n",
    "fig.savefig('compared_mean.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4821f2",
   "metadata": {},
   "source": [
    "#### Plot: Welch's T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.plot(x_axis,welch_t,\"g-\",label =\"Welch's T-value\")\n",
    "plt.plot(x_axis,welch_critical_value,\"r-\",linewidth=3,label =\"Corresponding Critical Value\")\n",
    "plt.title(\"Welch's T-test\", loc='bottom')\n",
    "plt.ylabel(\"T-Value\")\n",
    "plt.xlabel(\"Cycle\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('welch_t_test.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a1985",
   "metadata": {},
   "source": [
    "#### Plot: Variance Comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.semilogy(x_axis,var_area_estimate_ss,\"g-\",label =\"Variance Strategic Sampling\")\n",
    "plt.semilogy(x_axis,var_area_estimate_mc,\"b-\",label =\"Variance Monte Carlo\")\n",
    "#plt.ylim(-2,2)\n",
    "#plt.xlim(-2,2)\n",
    "plt.title(\"Variance Comparisson\", loc='bottom')\n",
    "plt.ylabel(\"Logarithmic Variance for sample Mean\")\n",
    "plt.xlabel(\"Cycle\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('logvariance_diff.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab988d5",
   "metadata": {},
   "source": [
    "#### Plot: One-sided F-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.semilogy(x_axis,F_tdivide,\"g-\",label =\"F-Value per Cycle\")\n",
    "plt.axhline(1.39,linewidth=3,color=\"red\",label =\"Critical F-Value\")\n",
    "#plt.ylim(-2,2)\n",
    "#plt.xlim(-2,2)\n",
    "plt.title(\"One-sided F-Test\", loc='bottom')\n",
    "plt.ylabel(\"Logarithmic F-Value\")\n",
    "plt.xlabel(\"Cycle\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('one_sided_f_test.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dcaf52",
   "metadata": {},
   "source": [
    "#### Settings for the sample Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_in_arr = [len(samplepoints_ss[i]) for i in range(len(samplepoints_ss))]\n",
    "samples_in_arr\n",
    "#ccolors = [\"ko\",\"g.\"]\n",
    "ccolors = [\"ko\", \"ko\",\"r.\",\"b.\",\"g.\"]\n",
    "#ccolors = [\"ko\",\"ko\",\"ko\",\"r.\",\"r.\",\"r.\",\"b.\",\"b.\",\"g.\",\"g.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9957d5",
   "metadata": {},
   "source": [
    "#### Samples in first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax = plt.subplots(1)\n",
    "orthos = np.transpose(samplepoints_ss[0])\n",
    "plt.plot(orthos[0],orthos[1], ccolors[4],linewidth=0.001)\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.title(\"Samples taken in the 1st Cycle\", loc='bottom')\n",
    "plt.ylabel(\"Imaginary Part\")\n",
    "plt.xlabel(\"Real Part\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('samples_cycle_1.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d9dc1",
   "metadata": {},
   "source": [
    "#### Samples in the second iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7300754",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax = plt.subplots(1)\n",
    "orthos = np.transpose(samplepoints_ss[1])\n",
    "plt.plot(orthos[0],orthos[1], ccolors[4],linewidth=0.001)\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.title(\"Samples taken in the 2nd Cycle\", loc='bottom')\n",
    "plt.ylabel(\"Imaginary Part\")\n",
    "plt.xlabel(\"Real Part\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('samples_cycle_2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e3291",
   "metadata": {},
   "source": [
    "#### Samples in the third iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax = plt.subplots(1)\n",
    "orthos = np.transpose(samplepoints_ss[2])\n",
    "plt.plot(orthos[0],orthos[1], ccolors[4],linewidth=0.001)\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.title(\"Samples taken in the 3rd Cycle\", loc='bottom')\n",
    "plt.ylabel(\"Imaginary Part\")\n",
    "plt.xlabel(\"Real Part\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('samples_cycle_3.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2dc641",
   "metadata": {},
   "source": [
    "#### Samples in the fourth iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax = plt.subplots(1)\n",
    "orthos = np.transpose(samplepoints_ss[3])\n",
    "plt.plot(orthos[0],orthos[1], ccolors[4],linewidth=0.001)\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.title(\"Samples taken in the 4th Cycle\", loc='bottom')\n",
    "plt.ylabel(\"Imaginary Part\")\n",
    "plt.xlabel(\"Real Part\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('samples_cycle_4.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682af88",
   "metadata": {},
   "source": [
    "#### Samples in the fifth iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f775698",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax = plt.subplots(1)\n",
    "orthos = np.transpose(samplepoints_ss[4])\n",
    "plt.plot(orthos[0],orthos[1], ccolors[4],linewidth=0.001)\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.title(\"Samples taken in the 5th Cycle\", loc='bottom')\n",
    "plt.ylabel(\"Imaginary Part\")\n",
    "plt.xlabel(\"Real Part\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('samples_cycle_5.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc08c5",
   "metadata": {},
   "source": [
    "#### Samples in the sixth iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40593bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fig, ax = plt.subplots(1)\n",
    "orthos = np.transpose(samplepoints_ss[5])\n",
    "plt.plot(orthos[0],orthos[1], ccolors[4],linewidth=0.001)\n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.title(\"Samples taken in the 6th Cycle\", loc='bottom')\n",
    "plt.ylabel(\"Imaginary Part\")\n",
    "plt.xlabel(\"Real Part\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig('samples_cycle_6.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
